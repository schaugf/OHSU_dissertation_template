@article{Radford2015,
abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
archivePrefix = {arXiv},
arxivId = {1511.06434},
author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
doi = {10.1051/0004-6361/201527329},
eprint = {1511.06434},
file = {:Users/schau/Library/Application Support/Mendeley Desktop/Downloaded/Radford, Metz, Chintala - 2015 - Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.pdf:pdf},
isbn = {2004012439},
issn = {0004-6361},
journal = {arXiv},
pages = {1--16},
pmid = {23459267},
title = {{Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1511.06434},
year = {2015}
}
@article{PEGORARO2017604,
author = {Pegoraro, Gianluca and Misteli, Tom},
doi = {https://doi.org/10.1016/j.tig.2017.06.005},
issn = {0168-9525},
journal = {Trends in Genetics},
keywords = { RNAi screening, chemical screening, fluorescence microscopy, high-content imaging, high-throughput imaging, phenotypic profiling,automation},
number = {9},
pages = {604--615},
title = {{High-Throughput Imaging for the Discovery of Cellular Mechanisms of Disease}},
url = {http://www.sciencedirect.com/science/article/pii/S0168952517301038},
volume = {33},
year = {2017}
}

@article{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
archivePrefix = {arXiv},
arxivId = {arXiv:1406.2661v1},
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
eprint = {arXiv:1406.2661v1},
file = {:Users/schau/Library/Application Support/Mendeley Desktop/Downloaded/Goodfellow, Pouget-Abadie, Mirza - 2014 - Generative Adversarial Networks.pdf:pdf},
isbn = {1406.2661},
issn = {10495258},
journal = {arXiv preprint},
mendeley-groups = {MachineLearning,qual},
pages = {1--9},
title = {{Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1406.2661},
year = {2014}
}


@article{Junttila2013,
author = {Junttila, Melissa R and de Sauvage, Frederic J},
journal = {Nature},
month = {sep},
pages = {346},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Influence of tumour micro-environment heterogeneity on therapeutic response}},
url = {https://doi.org/10.1038/nature12626 http://10.0.4.14/nature12626},
volume = {501},
year = {2013}
}

@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  publisher={GitHub},
  howpublished={\url{https://github.com/fchollet/keras}},
}

@article{massague2008tgfbeta,
  title={TGF$\beta$ in cancer},
  author={Massagu{\'e}, Joan},
  journal={Cell},
  volume={134},
  number={2},
  pages={215--230},
  year={2008},
  publisher={Elsevier}
}

@misc{Exacloud,
  title = {Advanced Computing Center and the Exacloud Cluster, OHSU. },
  howpublished = "\url{https://www.ohsu.edu/xd/ research/research-cores/advanced-computing-center/}",
}

@misc{Karpathy_tsne,
	title = {tSNE Visualization of CNN Codes},
	howpublished = "\url{https://cs.stanford.edu/people/karpathy/cnnembed/}"
}

@article{hu2018_ICLR, 
  title={On unifying deep generative models},
  author={Hu, Zhiting and Yang, Zichao and Salakhutdinov, Ruslan and Xing, Eric P},
  journal={arXiv preprint arXiv:1706.00550},
  year={2017}
}

@article{Abadi2016,
abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple com-putational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previ-ous " parameter server " designs the management of shared state is built into the system, TensorFlow enables develop-ers to experiment with novel optimizations and training al-gorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural net-works. Several Google services use TensorFlow in pro-duction, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that Tensor-Flow achieves for several real-world applications.},
archivePrefix = {arXiv},
arxivId = {1605.08695},
author = {Abadi, Mart{\'{i}}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang and Brain, Google},
eprint = {1605.08695},
file = {:home/schau/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abadi et al. - 2016 - TensorFlow A System for Large-Scale Machine Learning TensorFlow A system for large-scale machine learning.pdf:pdf},
isbn = {978-1-931971-33-1},
journal = {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI '16)},
pages = {265--284},
title = {{TensorFlow: A System for Large-Scale Machine Learning TensorFlow: A system for large-scale machine learning}},
url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi},
year = {2016}
}
@inproceedings{Burlingame2018,
author = {Burlingame, Erik A and Margolin, Adam and Gray, Joe W and Chang, Young Hwan},
booktitle = {SPIE},
pages = {1058105--1058107},
title = {{SHIFT: speedy histopathological-to-immunofluorescent translation of whole slide images using conditional generative adversarial networks}},
url = {https://doi.org/10.1117/12.2293249},
volume = {10581},
year = {2018}
}
@article{Caicedo2017,
abstract = {Image-based cell profiling is a high-throughput strategy for the quantification of phenotypic differences among a variety of cell populations. It paves the way to studying biological systems on a large scale by using chemical and genetic perturbations. The general workflow for this technology involves image acquisition with high- throughput microscopy systems and subsequent image processing and analysis. Here, we introduce the steps required to create high-quality image-based (i.e., morphological) profiles from a collection of microscopy images. We recommend techniques that have proven useful in each stage of the data analysis process, on the basis of the experience of 20 laboratories worldwide that are refining their image-based cell-profiling methodologies in pursuit of biological discovery. The recommended techniques cover alternatives that may suit various biological goals, experimental designs, and laboratories' preferences.},
author = {Caicedo, Juan C. and Cooper, Sam and Heigwer, Florian and Warchal, Scott and Qiu, Peng and Molnar, Csaba and Vasilevich, Aliaksei S. and Barry, Joseph D. and Bansal, Harmanjit Singh and Kraus, Oren and Wawer, Mathias and Paavolainen, Lassi and Herrmann, Markus D. and Rohban, Mohammad and Hung, Jane and Hennig, Holger and Concannon, John and Smith, Ian and Clemons, Paul A. and Singh, Shantanu and Rees, Paul and Horvath, Peter and Linington, Roger G. and Carpenter, Anne E.},
doi = {10.1038/nmeth.4397},
file = {:home/schau/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caicedo et al. - 2017 - Data-analysis strategies for image-based cell profiling.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
number = {9},
pages = {849--863},
pmid = {28858338},
title = {{Data-analysis strategies for image-based cell profiling}},
volume = {14},
year = {2017}
}
@article{Carpenter2006,
abstract = {Biologists can now prepare and image thousands of samples per day using automation, enabling chemical screens and functional genomics (for example, using RNA interference). Here we describe the first free, open-source system designed for flexible, high-throughput cell image analysis, CellProfiler. CellProfiler can address a variety of biological questions quantitatively, including standard assays (for example, cell count, size, per-cell protein levels) and complex morphological assays (for example, cell/organelle shape or subcellular patterns of DNA or protein staining). Rationale},
author = {Carpenter, Anne E. and Jones, Thouis R. and Lamprecht, Michael R. and Clarke, Colin and Kang, In Han and Friman, Ola and Guertin, David A. and Chang, Joo Han and Lindquist, Robert A and Moffat, Jason and Golland, Polina and Sabatini, David M.},
doi = {10.1186/gb-2006-7-10-r100},
file = {:home/schau/Dropbox/ref/cellprofiler.pdf:pdf},
issn = {17683254},
journal = {Genome Biol},
keywords = {CellProfiler},
number = {10},
pages = {R100},
title = {{CellProfiler: image analysis software for identifying and quantifying cell phenotypes}},
volume = {7},
year = {2006}
}
@article{Ching2017,
author = {Ching, Travers and Himmelstein, Daniel S and Beaulieu-jones, Brett K and Kalinin, A and Do, Brian T and Way, Gregory P and Ferrero, Enrico and Xie, Wei and Rosen, Gail L and Lengerich, Benjamin J and Israeli, Johnny},
file = {:home/schau/Dropbox/ref/142760.full.pdf:pdf},
journal = {bioRxiv},
keywords = {deep learning,genomic,precision medicine,review},
title = {{Opportunities and obstacles for deep learning in biology and medicine}},
year = {2017}
}
@article{Christiansen2018,
abstract = {Microscopy is a central method in life sciences. Many popular methods, such as antibody labeling, are used to add physical fluorescent labels to specific cellular constituents. However, these approaches have significant drawbacks, including inconsistency; limitations in the number of simultaneous labels because of spectral overlap; and necessary perturbations of the experiment, such as fixing the cells, to generate the measurement. Here, we show that a computational machine-learning approach, which we call “in silico labeling” (ISL), reliably predicts some fluorescent labels from transmitted-light images of unlabeled fixed or live biological samples. ISL predicts a range of labels, such as those for nuclei, cell type (e.g., neural), and cell state (e.g., cell death). Because prediction happens in silico, the method is consistent, is not limited by spectral overlap, and does not disturb the experiment. ISL generates biological measurements that would otherwise be problematic or impossible to acquire. In silico labeling, a machine-learning approach, reliably infers fluorescent measurements from transmitted-light images of unlabeled fixed or live biological samples.},
author = {Christiansen, Eric M. and Yang, Samuel J. and Ando, D. Michael and Javaherian, Ashkan and Skibinski, Gaia and Lipnick, Scott and Mount, Elliot and O'Neil, Alison and Shah, Kevan and Lee, Alicia K. and Goyal, Piyush and Fedus, William and Poplin, Ryan and Esteva, Andre and Berndl, Marc and Rubin, Lee L. and Nelson, Philip and Finkbeiner, Steven},
doi = {10.1016/j.cell.2018.03.040},
file = {:home/schau/Dropbox/ref/1-s2.0-S0092867418303647-main.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {cancer,computer vision,deep learning,machine learning,microscopy,neuroscience,stem cells},
number = {3},
pages = {792--795.e19},
pmid = {29656897},
publisher = {Elsevier Inc.},
title = {{In Silico Labeling: Predicting Fluorescent Labels in Unlabeled Images}},
url = {https://doi.org/10.1016/j.cell.2018.03.040},
volume = {173},
year = {2018}
}
@article{Ding2017,
author = {Ding, Jiarui and Condon, Anne and Shah, Sohrab P},
file = {:home/schau/Dropbox/ref/178624.full.pdf:pdf},
journal = {bioRxiv},
keywords = {deep learning,dimension reduction,els,latent variable models,probabilistic graphical mod-,single-cell rna-sequencing,variational inference},
title = {{Interpretable dimensionality reduction of single cell transcriptome data with deep generative models}},
year = {2017}
}
@article{Eulenberg2017,
abstract = {We show that deep convolutional neural networks combined with nonlinear dimension reduction enable reconstructing biological processes based on raw image data. We demonstrate this by reconstructing the cell cycle of Jurkat cells and disease progression in diabetic retinopathy. In further analysis of Jurkat cells, we detect and separate a subpopulation of dead cells in an unsupervised manner and, in classifying discrete cell cycle stages, we reach a sixfold reduction in error rate compared to a recent approach based on boosting on image features. In contrast to previous methods, deep learning based predictions are fast enough for on-the-fly analysis in an imaging flow cytometer.},
author = {Eulenberg, Philipp and K{\"{o}}hler, Niklas and Blasi, Thomas and Filby, Andrew and Carpenter, Anne E. and Rees, Paul and Theis, Fabian J. and Wolf, F. Alexander},
doi = {10.1038/s41467-017-00623-3},
file = {:home/schau/Dropbox/ref/s41467-017-00623-3.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
number = {1},
pages = {1--6},
pmid = {28878212},
publisher = {Springer US},
title = {{Reconstructing cell cycle and disease progression using deep learning}},
url = {http://dx.doi.org/10.1038/s41467-017-00623-3},
volume = {8},
year = {2017}
}
@article{Fleiss1973,
author = {Fleiss, Joseph L.},
file = {:home/schau/Dropbox/ref/001316447303300309.pdf:pdf},
journal = {Education and Psychological Measurement},
pages = {613--619},
title = {{The Equivalence of Weighted Kappa and the Interclass Correlation Coefficient as Measures of Reliability}},
volume = {33},
year = {1973}
}
@article{Goldsborough2017,
abstract = {We explore the application of Generative Adversarial Networks to the domain of morphological profiling of human cultured cells imaged by fluorescence microscopy. When evaluated for their ability to group cell images responding to treatment by chemicals of known classes, we find that adversarially learned representations are superior to autoencoder-based approaches. While currently inferior to classical computer vision and transfer learning, the adversarial framework enables useful visualization of the variation of cellular images due to their generative capabilities.},
author = {Goldsborough, Peter and Pawlowski, Nick and Caicedo, Juan C and Singh, Shantanu and Carpenter, Anne},
doi = {10.1101/227645},
file = {:home/schau/Dropbox/ref/227645.full.pdf:pdf},
journal = {bioRxiv},
number = {Nips},
pages = {227645},
title = {{CytoGAN: Generative Modeling of Cell Images}},
url = {https://www.biorxiv.org/content/early/2017/12/02/227645.full.pdf+html{\%}0Ahttps://www.biorxiv.org/content/early/2017/12/02/227645},
year = {2017}
}
@article{Kingma2013,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P and Welling, Max},
doi = {10.1051/0004-6361/201527329},
eprint = {1312.6114},
file = {:home/schau/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kingma, Welling - 2013 - Auto-Encoding Variational Bayes.pdf:pdf},
isbn = {1312.6114v10},
issn = {1312.6114v10},
journal = {arXiv preprint},
number = {Ml},
pages = {1--14},
pmid = {23459267},
title = {{Auto-Encoding Variational Bayes}},
url = {http://arxiv.org/abs/1312.6114},
year = {2013}
}
@article{Larsen2015,
abstract = {We present an autoencoder that leverages learned representations to better measure similarities in data space. By combining a variational autoencoder with a generative adversarial network we can use learned feature representations in the GAN discriminator as basis for the VAE reconstruction objective. Thereby, we replace element-wise errors with feature-wise errors to better capture the data distribution while offering invariance towards e.g. translation. We apply our method to images of faces and show that it outperforms VAEs with element-wise similarity measures in terms of visual fidelity. Moreover, we show that the method learns an embedding in which high-level abstract visual features (e.g. wearing glasses) can be modified using simple arithmetic.},
archivePrefix = {arXiv},
arxivId = {1512.09300},
author = {Larsen, Anders Boesen Lindbo and S{\o}nderby, S{\o}ren Kaae and Larochelle, Hugo and Winther, Ole},
eprint = {1512.09300},
file = {:home/schau/Dropbox/ref/1512.09300.pdf:pdf},
isbn = {9781510829008},
journal = {arXiv preprint},
title = {{Autoencoding beyond pixels using a learned similarity metric}},
url = {http://arxiv.org/abs/1512.09300},
year = {2015}
}
@article{Lin2017,
abstract = {Tumor microenvironments are a driver of resistance to anti-cancer drugs. Dissecting cell-microenvironment interactions into tractable units of study presents a challenge. Here, we assess the impact of hundreds of tumor-inspired microenvironments, in parallel, on lapatinib responses in four cancer cell lines. Combinations of ECM and soluble factors were printed on stiffness-tunable substrata to generate a collection of controlled microenvironments in which to explore cell-based functional responses. Proliferation, HER2 protein expression and phosphorylation, and morphology were measured in single cells. Using dimension reduction and linear modeling, the effects of microenvironment constituents were identified and then validated empirically. Each of the cell lines exhibits unique microenvironment-response patterns. Fibronectin, type IV collagen, and matrix rigidity are significant regulators of lapatinib resistance in HER2-amplified breast cancer cells. Small-molecule inhibitors were identified that could attenuate microenvironment-imposed resistance. Thus, we demonstrate a strategy to identify resistance- and sensitivity-driving microenvironments to improve the efficacy of anti-cancer therapeutics. Tumor microenvironments are a driver of anti-cancer drug resistance. Lin et al. use microenvironment microarrays and a cell-based functional approach to identify microenvironment components that modulate lapatinib responses in isogenic cells. They demonstrate a strategy to identify resistance- and sensitivity-driving microenvironments that may improve the understanding and efficacy of anti-cancer therapeutics.},
author = {Lin, Chun Han and Jokela, Tiina and Gray, Joe and LaBarge, Mark A.},
doi = {10.1016/j.celrep.2017.09.058},
file = {:home/schau/Dropbox/ref/PIIS2211124717313487.pdf:pdf},
issn = {22111247},
journal = {Cell Reports},
keywords = {AZD0530,HER2,MEMA,YAP,breast cancer,drug resistance,fibronectin,lapatinib,microenvironment,microenvironment microarray,verteporfin},
number = {2},
pages = {533--545},
pmid = {29020637},
publisher = {ElsevierCompany.},
title = {{Combinatorial Microenvironments Impose a Continuum of Cellular Responses to a Single Pathway-Targeted Anti-cancer Compound}},
url = {https://doi.org/10.1016/j.celrep.2017.09.058},
volume = {21},
year = {2017}
}
@article{Lin2012,
abstract = {The interactions between cells and their surrounding microenvironment have functional consequences for cellular behaviour. On the single cell level, distinct microenvironments can impose differentiation, migration, and proliferation phenotypes, and on the tissue level the microenvironment processes as complex as morphogenesis and tumorigenesis(1). Not only do the cell and molecular contents of microenvironments impact the cells within, but so do the elasticity(2) and geometry(3) of the tissue. Defined as the sum total of cell-cell, -ECM, and -soluble factor interactions, in addition to physical characteristics, the microenvironment is complex. The phenotypes of cells within a tissue are partially due to their genomic content and partially due to the combinatorial interactions with the microenviroment. A major challenge is to link specific combinations of microenvironmental components with distinctive behaviours. Here, we present the microenvironment microarray (MEArray) platform for cell-based functional screening of interactions with combinatorial microenvironments(4). The method allows for simultaneous control of the molecular composition and the elastic modulus, and combines the use of widely available microarray and micropatterning technologies. MEArray screens require as few as 10,000 cells per array, which facilitates functional studies of rare cell types such as adult progenitor cells. A limitation of the technology is that entire tissue microenvironments cannot be completely recapitulated on MEArrays. However, comparison of responses in the same cell type to numerous related microenvironments, for instance pairwise combinations of ECM proteins that characterize a given tissue, will provide insights into how microenvironmental components elicit tissue-specific functional phenotypes. MEArrays can be printed using a wide variety of recombinant growth factors, cytokines, and purified ECM proteins, and combinations thereof. The platform is limited only by the availability of specific reagents. MEArrays are amenable to time-lapsed analysis, but most often are used for end point analyses of cellular functions that are measureable with fluorescent probes. For instance, DNA synthesis, apoptosis, acquisition of differentiated states, or production of specific gene products are commonly measured. Briefly, the basic flow of an MEArray experiment is to prepare slides coated with printing substrata and to prepare the master plate of proteins that are to be printed. Then the arrays are printed with a microarray robot, cells are allowed to attach, grow in culture, and then are chemically fixed upon reaching the experimental endpoint. Fluorescent or colorimetric assays, imaged with traditional microscopes or microarray scanners, are used to reveal relevant molecular and cellular phenotypes (Figure 1).},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Lin, Chun-Han and Lee, Jonathan K. and LaBarge, Mark A.},
doi = {10.3791/4152},
eprint = {NIHMS150003},
file = {:home/schau/Dropbox/ref/jove-68-4152.pdf:pdf},
isbn = {0000000000000},
issn = {1940-087X},
journal = {Journal of Visualized Experiments},
keywords = {10,11,2012,68,a,assay,biochemistry,biophysics,c,cell culture,cellular biology,citation,date published,e4152,exp,fabrication and use of,functional cell-based,issue 68,j,k,labarge,lee,lin,m,mearray,mearrays,microarray,microenvironment,microenvironment microarrays,molecular biology,pdms,vis},
number = {68},
pages = {1--7},
pmid = {23093325},
title = {{Fabrication and Use of MicroEnvironment microArrays (MEArrays)}},
url = {http://www.jove.com/video/4152/fabrication-and-use-of-microenvironment-microarrays-mearrays},
year = {2012}
}
@article{Lopez2017,
abstract = {We propose a probabilistic model for interpreting gene expression levels that are observed through single-cell RNA sequencing. In the model, each cell has a low-dimensional latent representation. Additional latent variables account for technical effects that may erroneously set some observations of gene expression levels to zero. Conditional distributions are specified by neural networks, giving the proposed model enough flexibility to fit the data well. We use variational inference and stochastic optimization to approximate the posterior distribution. The inference procedure scales to over one million cells, whereas competing algorithms do not. Even for smaller datasets, for several tasks, the proposed procedure outperforms state-of-the-art methods like ZIFA and ZINB-WaVE. We also extend our framework to account for batch effects and other confounding factors, and propose a Bayesian hypothesis test for differential expression that outperforms DESeq2.},
archivePrefix = {arXiv},
arxivId = {1709.02082},
author = {Lopez, Romain and Regier, Jeffrey and Cole, Michael and Jordan, Michael and Yosef, Nir},
eprint = {1709.02082},
file = {:home/schau/Dropbox/ref/1709.02082v3.pdf:pdf},
journal = {arXiv},
title = {{A deep generative model for gene expression profiles from single-cell RNA sequencing}},
url = {http://arxiv.org/abs/1709.02082},
year = {2017}
}
@article{Makhzani2015,
abstract = {In this paper, we propose the "adversarial autoencoder" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks.},
archivePrefix = {arXiv},
arxivId = {1511.05644},
author = {Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},
eprint = {1511.05644},
file = {:home/schau/Dropbox/ref/1511.05644.pdf:pdf},
isbn = {9781509008063},
journal = {arXiv},
title = {{Adversarial Autoencoders}},
url = {http://arxiv.org/abs/1511.05644},
year = {2015}
}
@article{Pu2016,
abstract = {A novel variational autoencoder is developed to model images, as well as associated labels or captions. The Deep Generative Deconvolutional Network (DGDN) is used as a decoder of the latent image features, and a deep Convolutional Neural Network (CNN) is used as an image encoder; the CNN is used to approximate a distribution for the latent DGDN features/code. The latent code is also linked to generative models for labels (Bayesian support vector machine) or captions (recurrent neural network). When predicting a label/caption for a new image at test, averaging is performed across the distribution of latent codes; this is computationally efficient as a consequence of the learned CNN-based encoder. Since the framework is capable of modeling the image in the presence/absence of associated labels/captions, a new semi-supervised setting is manifested for CNN learning with images; the framework even allows unsupervised CNN learning, based on images alone.},
archivePrefix = {arXiv},
arxivId = {1609.08976},
author = {Pu, Yunchen and Gan, Zhe and Henao, Ricardo and Yuan, Xin and Li, Chunyuan and Stevens, Andrew and Carin, Lawrence},
eprint = {1609.08976},
file = {:home/schau/Dropbox/ref/6528-variational-autoencoder-for-deep-learning-of-images-labels-and-captions.pdf:pdf},
issn = {10495258},
journal = {NIPS},
number = {Nips},
title = {{Variational Autoencoder for Deep Learning of Images, Labels and Captions}},
url = {http://arxiv.org/abs/1609.08976},
year = {2016}
}
@article{VanDerMaaten2008a,
abstract = {We present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence theway in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualiza- tions produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
archivePrefix = {arXiv},
arxivId = {1307.1662},
author = {{Van Der Maaten}, L J P and Hinton, G E},
doi = {10.1007/s10479-011-0841-3},
eprint = {1307.1662},
file = {:home/schau/Dropbox/ref/vandermaaten08a.pdf:pdf},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {dimensionality reduction,embedding algorithms,manifold learning,multidimensional scaling,visualization},
pages = {2579--2605},
pmid = {20652508},
title = {{Visualizing high-dimensional data using t-sne}},
url = {https://lvdmaaten.github.io/publications/papers/JMLR{\_}2008.pdf{\%}0Ahttp://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=pubmed{\&}cmd=Retrieve{\&}dopt=AbstractPlus{\&}list{\_}uids=7911431479148734548related:VOiAgwMNy20J},
volume = {9},
year = {2008}
}
@article{Watson2018,
abstract = {Extrinsic signals are implicated in breast cancer resistance to HER2-targeted tyrosine kinase inhibitors (TKIs). To examine how microenvironmental signals influence resistance, we monitored TKI-treated breast cancer cell lines grown on microenvironment microarrays composed of printed extracellular matrix proteins supplemented with soluble proteins. We tested {\~{}}2,500 combinations of 56 soluble and 46 matrix microenvironmental proteins on basal-like HER2+ (HER2E) or luminal-like HER2+ (L-HER2+) cells treated with the TKIs lapatinib or neratinib. In HER2E cells, hepatocyte growth factor, a ligand for MET, induced resistance that could be reversed with crizotinib, an inhibitor of MET. In L-HER2+ cells, neuregulin1-$\beta$1 (NRG1$\beta$), a ligand for HER3, induced resistance that could be reversed with pertuzumab, an inhibitor of HER2-HER3 heterodimerization. The subtype-specific responses were also observed in 3D cultures and murine xenografts. These results, along with bioinformatic pathway analysis and siRNA knockdown experiments, suggest different mechanisms of resistance specific to each HER2+ subtype: MET signaling for HER2E and HER2-HER3 heterodimerization for L-HER2+ cells. We describe a powerful platform for discovery of microenvironment signals that influence drug responses. We show through application of the platform to HER2+ breast cancer cell lines that NRG1$\beta$ and HGF suppress responses to lapatinib and neratinib in L-HER2+ and HER2E cells, respectively. We show that these differences are caused by differences in epigenomic status and regulatory pathway use between L-HER2+ and HER2E breast cancers. We also present evidence suggesting that microenvironment-mediated resistance to HER2-targeted tyrosine kinase inhibitors can be overcome in L-HER2+ cancers by co-treatment with pertuzumab, and in HER2E cancers by co-treatment with crizotinib or trametinib.},
author = {Watson, Spencer S. and Dane, Mark and Chin, Koei and Tatarova, Zuzana and Liu, Moqing and Liby, Tiera and Thompson, Wallace and Smith, Rebecca and Nederlof, Michel and Bucher, Elmar and Kilburn, David and Whitman, Matthew and Sudar, Damir and Mills, Gordon B. and Heiser, Laura M. and Jonas, Oliver and Gray, Joe W. and Korkola, James E.},
doi = {10.1016/j.cels.2018.02.001},
file = {:home/schau/Dropbox/ref/PIIS2405471218300541.pdf:pdf},
issn = {24054720},
journal = {Cell Systems},
keywords = {Crizotinib,Drug resistance,HER2+ breast cancer subtypes,HER3,HGF,Lapatinib,Microenvironment,NRG1$\beta$,Neratinib,Pertuzumab},
number = {3},
pages = {329--342.e6},
pmid = {29550255},
publisher = {Elsevier Inc.},
title = {{Microenvironment-Mediated Mechanisms of Resistance to HER2 Inhibitors Differ between HER2+ Breast Cancer Subtypes}},
url = {https://doi.org/10.1016/j.cels.2018.02.001},
volume = {6},
year = {2018}
}
@article{Way2018,
abstract = {The Cancer Genome Atlas (TCGA) has profiled over 10,000 tumors across 33 different cancer-types for many genomic features, including gene expression levels. Gene expression measurements capture substantial information about the state of each tumor. Certain classes of deep neural network models are capable of learning a meaningful latent space. Such a latent space could be used to explore and generate hypothetical gene expression profiles under various types of molecular and genetic perturbation. For example, one might wish to use such a model to predict a tumor's response to specific therapies or to characterize complex gene expression activations existing in differential proportions in different tumors. Variational autoencoders (VAEs) are a deep neural network approach capable of generating meaningful latent spaces for image and text data. In this work, we sought to determine the extent to which a VAE can be trained to model cancer gene expression, and whether or not such a VAE would capture biologically-relevant features. In the following report, we introduce a VAE trained on TCGA pan-cancer RNA-seq data, identify specific patterns in the VAE encoded features, and discuss potential merits of the approach. We name our method "Tybalt" after an instigative, cat-like character who sets a cascading chain of events in motion in Shakespeare's "Romeo and Juliet". From a systems biology perspective, Tybalt could one day aid in cancer stratification or predict specific activated expression patterns that would result from genetic changes or treatment effects.},
author = {Way, Gregory P and Greene, Casey S},
doi = {10.1101/174474},
file = {:home/schau/Dropbox/ref/way.pdf:pdf},
isbn = {978-981-323-552-6},
issn = {2335-6936},
journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
keywords = {deep learning,gene expression,the cancer genome,variational autoencoder},
pages = {80--91},
pmid = {29218871},
title = {{Extracting a biologically relevant latent space from cancer transcriptomes with variational autoencoders.}},
volume = {23},
year = {2018}
}
@article{Zamparo2015,
abstract = {High-content screening uses large collections of unlabeled cell image data to reason about genetics or cell biology. Two important tasks are to identify those cells which bear interesting phenotypes, and to identify sub-populations enriched for these phenotypes. This exploratory data analysis usually involves dimensionality reduction followed by clustering, in the hope that clusters represent a phenotype. We propose the use of stacked de-noising auto-encoders to perform dimensionality reduction for high-content screening. We demonstrate the superior performance of our approach over PCA, Local Linear Embedding, Kernel PCA and Isomap.},
archivePrefix = {arXiv},
arxivId = {1501.01348},
author = {Zamparo, Lee and Zhang, Zhaolei},
eprint = {1501.01348},
file = {:home/schau/Dropbox/ref/1501.01348.pdf:pdf},
journal = {arXiv preprint},
pages = {1--5},
title = {{Deep Autoencoders for Dimensionality Reduction of High-Content Screening Data}},
url = {http://arxiv.org/abs/1501.01348},
year = {2015}
}

